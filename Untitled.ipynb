{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "train = pd.read_csv('dataset_portion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>449436</td>\n",
       "      <td>I have no idea how someone can give this anyth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>449450</td>\n",
       "      <td>no stars-my dog got so sick from these and aft...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>449452</td>\n",
       "      <td>\"No artificial color, no fillers\"... I bought ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>449461</td>\n",
       "      <td>People need to do research - this is crap stuf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>449485</td>\n",
       "      <td>I have purchased many of this kind of chew for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  Score\n",
       "0      449436  I have no idea how someone can give this anyth...      1\n",
       "1      449450  no stars-my dog got so sick from these and aft...      1\n",
       "2      449452  \"No artificial color, no fillers\"... I bought ...      1\n",
       "3      449461  People need to do research - this is crap stuf...      1\n",
       "4      449485  I have purchased many of this kind of chew for...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train['Score']\n",
    "#print(len(train_label))\n",
    "train_sent = train['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "UniVec = CountVectorizer(max_features = 500, ngram_range = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "uni = UniVec.fit_transform(train_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(113689, 500)\n",
      "(113689,)\n"
     ]
    }
   ],
   "source": [
    "print(uni.shape)\n",
    "print(train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6452955933343395"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "acc = []\n",
    "for train_index, test_index in skf.split(uni, train_label):\n",
    "    x_train,x_test = uni[train_index], uni[test_index]\n",
    "    y_train, y_test = train_label[train_index], train_label[test_index]\n",
    "    NB.fit(x_train, y_train)\n",
    "    acc.append(NB.score(x_test, y_test))\n",
    "acc = np.asarray(acc)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6398770903829912"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc = Perceptron()\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "acc = []\n",
    "for train_index, test_index in skf.split(uni, train_label):\n",
    "    x_train,x_test = uni[train_index], uni[test_index]\n",
    "    y_train, y_test = train_label[train_index], train_label[test_index]\n",
    "    pc.fit(x_train, y_train)\n",
    "    acc.append(pc.score(x_test, y_test))\n",
    "acc = np.asarray(acc)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6813939130862192"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = LinearSVC()\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "acc = []\n",
    "for train_index, test_index in skf.split(uni, train_label):\n",
    "    x_train,x_test = uni[train_index], uni[test_index]\n",
    "    y_train, y_test = train_label[train_index], train_label[test_index]\n",
    "    svm.fit(x_train, y_train)\n",
    "    acc.append(svm.score(x_test, y_test))\n",
    "acc = np.asarray(acc)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6862668726847836"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "acc = []\n",
    "for train_index, test_index in skf.split(uni, train_label):\n",
    "    x_train,x_test = uni[train_index], uni[test_index]\n",
    "    y_train, y_test = train_label[train_index], train_label[test_index]\n",
    "    lr.fit(x_train, y_train)\n",
    "    acc.append(lr.score(x_test, y_test))\n",
    "acc = np.asarray(acc)\n",
    "acc.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(uni, train_label,random_state = 442,train_size = 0.8, test_size= 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = [NB, pc, svm, lr]\n",
    "for clf in clfs:\n",
    "    clf.fit(X_train, Y_train)\n",
    "    print(clf.score(X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
